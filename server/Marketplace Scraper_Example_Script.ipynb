{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad7fd475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import wget\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from splinter import Browser\n",
    "from selenium.webdriver.firefox.service import Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_facebook_marketplace_query(params):\n",
    "    '''Returns a URL for Facebook Marketplace given user parameters'''\n",
    "    # check for the two required parameters, if they are not specified, then exit\n",
    "    if 'location' not in params or 'item' not in params:\n",
    "        raise ValueError('location or item was not specified.')\n",
    "    \n",
    "    # make default params if they are not specified\n",
    "    if 'condition' not in params:\n",
    "        params['condition'] = []\n",
    "    \n",
    "    if 'min_price' not in params:\n",
    "        params['min_price'] = 0\n",
    "    \n",
    "    if 'max_price' not in params:\n",
    "        params['max_price'] = 1000\n",
    "    \n",
    "    if 'days_since_listed' not in params:\n",
    "        params['days_since_listed'] = 10\n",
    "\n",
    "    # lookup table for conditions \n",
    "    condition_separator = \"%2C\"\n",
    "    conditions = {0: \"new\", 1: \"used_like_new\", 2: \"used_good\", 3: \"used_fair\"}\n",
    "\n",
    "    # create the conditions part of url\n",
    "    condition = \"\" if params['condition'] == [] else \"&itemCondition=\" + conditions[params['condition'][0]]\n",
    "    for index in params['condition']:\n",
    "        condition += condition_separator + conditions[index]\n",
    "\n",
    "    # create the query string\n",
    "    base_url = f\"https://www.facebook.com/marketplace/{params['location']}/search?\"\n",
    "    url = f\"{base_url}minPrice={params['min_price']}&maxPrice={params['max_price']}&daysSinceListed={params['days_since_listed']}{condition}&query={params['item']}\"\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_marketplace_html(url):\n",
    "    \"\"\"Returns Facebook Marketplace Data in the format of BeautifulSoup Object\"\"\"\n",
    "    browser = Browser('firefox')\n",
    "    browser.visit(url)\n",
    "\n",
    "    # close pop out window\n",
    "    if browser.is_element_present_by_css('div[aria-label=\"Close\"]', wait_time=10):\n",
    "        # Click on the element once it's found\n",
    "        browser.find_by_css('div[aria-label=\"Close\"]').first.click()\n",
    "    \n",
    "    # Scroll down to load more results\n",
    "    \n",
    "    # Define the number of times to scroll the page\n",
    "    scroll_count = 4\n",
    "\n",
    "    # Define the delay (in seconds) between each scroll\n",
    "    scroll_delay = 2\n",
    "\n",
    "    # Loop to perform scrolling\n",
    "    for _ in range(scroll_count):\n",
    "        # Execute JavaScript to scroll to the bottom of the page\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        \n",
    "        # Pause for a moment to allow the content to load\n",
    "        time.sleep(scroll_delay)\n",
    "    \n",
    "    # Parse the HTML\n",
    "    html = browser.html\n",
    "\n",
    "    # close browser window\n",
    "    time.sleep(1)\n",
    "    browser.quit()\n",
    "\n",
    "    # Create a BeautifulSoup object from the scraped HTML\n",
    "    return soup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_marketplace_data(market_soup):\n",
    "    '''Returns a Pandas Data Frame with information about Facebook Marketplace listings'''\n",
    "\n",
    "    # get listings\n",
    "\n",
    "    listing_divs = market_soup.find_all('div', class_=\"x9f619 x78zum5 x1r8uery xdt5ytf x1iyjqo2 xs83m0k x1e558r4 x150jy0e x1iorvi4 xjkvuk6 xnpuxes x291uyu x1uepa24\")\n",
    "    data = []\n",
    "    for listing_div in listing_divs:\n",
    "        \n",
    "        # Extract all the necessary info and insert into lists\n",
    "        picture_div = listing_div.find('img', class_=\"xt7dq6l xl1xv1r x6ikm8r x10wlt62 xh8yej3\")\n",
    "        if picture_div == None:\n",
    "            continue\n",
    "        picture_url = picture_div.get('src')\n",
    "\n",
    "        title_div = listing_div.find('span', class_=\"x1lliihq x6ikm8r x10wlt62 x1n2onr6\")\n",
    "        if title_div == None:\n",
    "            continue\n",
    "        title = title_div.text.strip()\n",
    "\n",
    "        price_div = listing_div.find('span', class_=\"x193iq5w xeuugli x13faqbe x1vvkbs x1xmvt09 x1lliihq x1s928wv xhkezso x1gmr53x x1cpjm7i x1fgarty x1943h6x xudqn12 x676frb x1lkfr7t x1lbecb7 x1s688f xzsf02u\")\n",
    "        if price_div == None:\n",
    "            continue\n",
    "        price = price_div.text.strip()\n",
    "\n",
    "        location_div = listing_div.find('span', class_=\"x193iq5w xeuugli x13faqbe x1vvkbs x1xmvt09 x1lliihq x1s928wv xhkezso x1gmr53x x1cpjm7i x1fgarty x1943h6x x4zkp8e x3x7a5m x1nxh6w3 x1sibtaa xo1l8bm xi81zsa\")\n",
    "        if location_div == None:\n",
    "            continue\n",
    "        location = location_div.text.strip()\n",
    "\n",
    "        url_div = listing_div.find('a', class_=\"x1i10hfl xjbqb8w x1ejq31n xd10rxx x1sy0etr x17r0tee x972fbf xcfux6l x1qhh985 xm0m39n x9f619 x1ypdohk xt0psk2 xe8uvvx xdj266r x11i5rnm xat24cr x1mh8g0r xexx8yu x4uap5 x18d9i69 xkhd6sd x16tdsg8 x1hl2dhg xggy1nq x1a2a7pz x1heor9g x1sur9pj xkrqix3 x1lku1pv\")\n",
    "        if url_div == None:\n",
    "            continue\n",
    "        url = \"www.facebook.com\" + url_div.get('href')\n",
    "\n",
    "        listing = {\n",
    "            'title': title,\n",
    "            'price': price,\n",
    "            'location': location,\n",
    "            'image_url': picture_url,\n",
    "            'url': url\n",
    "        }\n",
    "        data.append(listing)\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ebay_listings(item):\n",
    "    '''Returns a Pandas Data Frame with information about Ebay listings'''\n",
    "    ebay_url = f\"https://www.ebay.com/sch/i.html?_nkw={item}\"\n",
    "    response = requests.get(ebay_url)\n",
    "\n",
    "    ebay_soup = soup(response.text, 'html.parser')\n",
    "    \n",
    "    item_divs = ebay_soup.find_all('li', class_='s-item s-item__pl-on-bottom')\n",
    "\n",
    "    prices = [div.find('span', class_='s-item__price').text for div in item_divs]\n",
    "\n",
    "    urls = [div.find('a', class_='s-item__link').get('href') for div in item_divs]\n",
    "\n",
    "    \n",
    "    image_divs = [div.find('div', class_='s-item__image-wrapper image-treatment') for div in item_divs]\n",
    "    image_tags = [div.find('img') for div in image_divs]\n",
    "    image_urls = [url.get('src') for url in image_tags]\n",
    "\n",
    "    titles_div = [div.find('div', class_='s-item__title') for div in item_divs]\n",
    "    titles = [div.find('span').text for div in titles_div]\n",
    "\n",
    "    data = {\n",
    "        'title': titles,\n",
    "        'price': prices,\n",
    "        'image_url': image_urls,\n",
    "        'url': urls\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_ebay_listings(df):\n",
    "    \"\"\"Returns a cleaned data frame without any outliers\"\"\"\n",
    "    # remove any special characters and convert to float\n",
    "    df['price'] = df['price'].replace('[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "    # remove the first two rows\n",
    "    df = df.iloc[2:].reset_index(drop=True)\n",
    "\n",
    "    # Remove outliers in the 'Price' column\n",
    "    # Here we use the IQR method to identify outliers\n",
    "\n",
    "    Q1 = df['price'].quantile(0.25)\n",
    "    Q3 = df['price'].quantile(0.60)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Define lower and upper bound for outliers\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Filter out the outliers\n",
    "    df_cleaned = df[(df['price'] >= lower_bound) & (df['price'] <= upper_bound)]\n",
    "\n",
    "    return df_cleaned\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ebay_stats(df):\n",
    "    \"\"\"Returns a data frame with statistics of ebay listings\"\"\"\n",
    "    # Calculate key statistics\n",
    "    mean_price = df['price'].mean()\n",
    "    median_price = df['price'].median()\n",
    "    std_dev_price = df['price'].std()\n",
    "    fair_price = median_price * 1.05  # Adjust by 5% for current market trends\n",
    "\n",
    "    # store and return states in data frame\n",
    "    stats = {\n",
    "        'mean_price': [mean_price],\n",
    "        'median_price': [median_price],\n",
    "        'std_dev': [std_dev_price],\n",
    "        'fair_price': [fair_price]\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(stats).round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_google_lens(image_url):\n",
    "    \"\"\"Returns Google Lens Data in the format of BeautifulSoup Object\"\"\"\n",
    "    google_lens_url = f\"https://lens.google.com/uploadbyurl?url={image_url}\"\n",
    "    browser = Browser('firefox')\n",
    "    browser.visit(google_lens_url)\n",
    "    \n",
    "    time.sleep(1)\n",
    "    # Scroll down to load more results\n",
    "    \n",
    "    # Define the number of times to scroll the page\n",
    "    scroll_count = 2\n",
    "\n",
    "    # Define the delay (in seconds) between each scroll\n",
    "    scroll_delay = 2\n",
    "\n",
    "    # Loop to perform scrolling\n",
    "    for _ in range(scroll_count):\n",
    "        # Execute JavaScript to scroll to the bottom of the page\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        \n",
    "        # Pause for a moment to allow the content to load\n",
    "        time.sleep(scroll_delay)\n",
    "    \n",
    "    # Parse the HTML\n",
    "    html = browser.html\n",
    "\n",
    "    # close browser window\n",
    "    time.sleep(1)\n",
    "    browser.quit()\n",
    "\n",
    "    # Create a BeautifulSoup object from the scraped HTML\n",
    "    return soup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the parameters\n",
    "params = {\n",
    "    'location': \"pittsburgh\",\n",
    "    'item': \"jersey\",\n",
    "    'condition': [],\n",
    "    'min_price': 0,\n",
    "    'max_price': 100,\n",
    "    'days_since_listed': 10\n",
    "}\n",
    "\n",
    "# create the facebook marketplace query\n",
    "url = create_facebook_marketplace_query(params)\n",
    "\n",
    "# Visit the website and gather data\n",
    "market_soup = fetch_marketplace_html(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>location</th>\n",
       "      <th>image_url</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jerseys for sale</td>\n",
       "      <td>$20</td>\n",
       "      <td>Pittsburgh, PA</td>\n",
       "      <td>https://scontent-iad3-2.xx.fbcdn.net/v/t45.532...</td>\n",
       "      <td>www.facebook.com/marketplace/item/868062668532...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Soccer jerseys</td>\n",
       "      <td>$20</td>\n",
       "      <td>Carnegie, PA</td>\n",
       "      <td>https://scontent-iad3-1.xx.fbcdn.net/v/t45.532...</td>\n",
       "      <td>www.facebook.com/marketplace/item/452439987599...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pirates \"Bae\" Jersey</td>\n",
       "      <td>$30</td>\n",
       "      <td>Pittsburgh, PA</td>\n",
       "      <td>https://scontent-iad3-2.xx.fbcdn.net/v/t45.532...</td>\n",
       "      <td>www.facebook.com/marketplace/item/162519227499...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Paul Skenes Pittsburgh Pirates Jersey</td>\n",
       "      <td>$71</td>\n",
       "      <td>Pittsburgh, PA</td>\n",
       "      <td>https://scontent-iad3-2.xx.fbcdn.net/v/t45.532...</td>\n",
       "      <td>www.facebook.com/marketplace/item/217612536610...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pittsburgh Penguins Sidney Crosby Jersey</td>\n",
       "      <td>$20</td>\n",
       "      <td>Enterprise, WV</td>\n",
       "      <td>https://scontent-iad3-1.xx.fbcdn.net/v/t45.532...</td>\n",
       "      <td>www.facebook.com/marketplace/item/876438061182...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>dog jersey</td>\n",
       "      <td>$5</td>\n",
       "      <td>Tarentum, PA</td>\n",
       "      <td>https://scontent-iad3-2.xx.fbcdn.net/v/t45.532...</td>\n",
       "      <td>www.facebook.com/marketplace/item/117036414086...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Official Steeler Jersy (Med)</td>\n",
       "      <td>$50</td>\n",
       "      <td>Pittsburgh, PA</td>\n",
       "      <td>https://scontent-iad3-2.xx.fbcdn.net/v/t45.532...</td>\n",
       "      <td>www.facebook.com/marketplace/item/460539336827...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>**Like New** Harrison Smith Vikings #22 Purple...</td>\n",
       "      <td>$25</td>\n",
       "      <td>Carnegie, PA</td>\n",
       "      <td>https://scontent-iad3-2.xx.fbcdn.net/v/t45.532...</td>\n",
       "      <td>www.facebook.com/marketplace/item/503561708868...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Authentic Reebok Pittsburgh Steelers On Field ...</td>\n",
       "      <td>$75</td>\n",
       "      <td>Pittsburgh, PA</td>\n",
       "      <td>https://scontent-iad3-2.xx.fbcdn.net/v/t45.532...</td>\n",
       "      <td>www.facebook.com/marketplace/item/521558273771...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Greg Lloyd Pittsburgh Steelers MFL Jersey size XL</td>\n",
       "      <td>$30</td>\n",
       "      <td>Verona, PA</td>\n",
       "      <td>https://scontent-iad3-1.xx.fbcdn.net/v/t45.532...</td>\n",
       "      <td>www.facebook.com/marketplace/item/167287940681...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title price        location  \\\n",
       "0                                     Jerseys for sale   $20  Pittsburgh, PA   \n",
       "1                                       Soccer jerseys   $20    Carnegie, PA   \n",
       "2                                 Pirates \"Bae\" Jersey   $30  Pittsburgh, PA   \n",
       "3                Paul Skenes Pittsburgh Pirates Jersey   $71  Pittsburgh, PA   \n",
       "4             Pittsburgh Penguins Sidney Crosby Jersey   $20  Enterprise, WV   \n",
       "..                                                 ...   ...             ...   \n",
       "115                                         dog jersey    $5    Tarentum, PA   \n",
       "116                       Official Steeler Jersy (Med)   $50  Pittsburgh, PA   \n",
       "117  **Like New** Harrison Smith Vikings #22 Purple...   $25    Carnegie, PA   \n",
       "118  Authentic Reebok Pittsburgh Steelers On Field ...   $75  Pittsburgh, PA   \n",
       "119  Greg Lloyd Pittsburgh Steelers MFL Jersey size XL   $30      Verona, PA   \n",
       "\n",
       "                                             image_url  \\\n",
       "0    https://scontent-iad3-2.xx.fbcdn.net/v/t45.532...   \n",
       "1    https://scontent-iad3-1.xx.fbcdn.net/v/t45.532...   \n",
       "2    https://scontent-iad3-2.xx.fbcdn.net/v/t45.532...   \n",
       "3    https://scontent-iad3-2.xx.fbcdn.net/v/t45.532...   \n",
       "4    https://scontent-iad3-1.xx.fbcdn.net/v/t45.532...   \n",
       "..                                                 ...   \n",
       "115  https://scontent-iad3-2.xx.fbcdn.net/v/t45.532...   \n",
       "116  https://scontent-iad3-2.xx.fbcdn.net/v/t45.532...   \n",
       "117  https://scontent-iad3-2.xx.fbcdn.net/v/t45.532...   \n",
       "118  https://scontent-iad3-2.xx.fbcdn.net/v/t45.532...   \n",
       "119  https://scontent-iad3-1.xx.fbcdn.net/v/t45.532...   \n",
       "\n",
       "                                                   url  \n",
       "0    www.facebook.com/marketplace/item/868062668532...  \n",
       "1    www.facebook.com/marketplace/item/452439987599...  \n",
       "2    www.facebook.com/marketplace/item/162519227499...  \n",
       "3    www.facebook.com/marketplace/item/217612536610...  \n",
       "4    www.facebook.com/marketplace/item/876438061182...  \n",
       "..                                                 ...  \n",
       "115  www.facebook.com/marketplace/item/117036414086...  \n",
       "116  www.facebook.com/marketplace/item/460539336827...  \n",
       "117  www.facebook.com/marketplace/item/503561708868...  \n",
       "118  www.facebook.com/marketplace/item/521558273771...  \n",
       "119  www.facebook.com/marketplace/item/167287940681...  \n",
       "\n",
       "[120 rows x 5 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse html to create structured listing data\n",
    "facebook_listings = parse_marketplace_data(market_soup)\n",
    "facebook_listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '9.90 to 35.90'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m ebay_listings \u001b[38;5;241m=\u001b[39m get_ebay_listings(facebook_listings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m----> 2\u001b[0m ebay_listings \u001b[38;5;241m=\u001b[39m \u001b[43mfilter_ebay_listings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mebay_listings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m ebay_listings\n",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m, in \u001b[0;36mfilter_ebay_listings\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a cleaned data frame without any outliers\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# remove any special characters and convert to float\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m[\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m$,]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# remove the first two rows\u001b[39;00m\n\u001b[0;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m2\u001b[39m:]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\shake\\Desktop\\Projects\\Flip-Finder\\server\\env\\Lib\\site-packages\\pandas\\core\\generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   6639\u001b[0m     ]\n\u001b[0;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\shake\\Desktop\\Projects\\Flip-Finder\\server\\env\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\shake\\Desktop\\Projects\\Flip-Finder\\server\\env\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Users\\shake\\Desktop\\Projects\\Flip-Finder\\server\\env\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[0;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\shake\\Desktop\\Projects\\Flip-Finder\\server\\env\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\shake\\Desktop\\Projects\\Flip-Finder\\server\\env\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\shake\\Desktop\\Projects\\Flip-Finder\\server\\env\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:133\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '9.90 to 35.90'"
     ]
    }
   ],
   "source": [
    "ebay_listings = get_ebay_listings(facebook_listings['title'][0])\n",
    "ebay_listings = filter_ebay_listings(ebay_listings)\n",
    "ebay_listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_price</th>\n",
       "      <th>median_price</th>\n",
       "      <th>std_dev</th>\n",
       "      <th>fair_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83.57</td>\n",
       "      <td>79.0</td>\n",
       "      <td>43.96</td>\n",
       "      <td>82.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_price  median_price  std_dev  fair_price\n",
       "0       83.57          79.0    43.96       82.95"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebay_stats = calc_ebay_stats(ebay_listings)\n",
    "ebay_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to upload image\n",
      "Status code: 400\n",
      "Response: <html lang=en><meta charset=utf-8><meta name=viewport content=\"initial-scale=1, minimum-scale=1, width=device-width\"><title>Error 400 (Bad Request)!!1</title><style nonce=\"UCXaO5XPaGz3wdU3w45zzQ\">*{margin:0;padding:0}html,code{font:15px/22px arial,sans-serif}html{background:#fff;color:#222;padding:15px}body{color:#222;text-align:unset;margin:7% auto 0;max-width:390px;min-height:180px;padding:30px 0 15px;}* > body{background:url(//www.google.com/images/errors/robot.png) 100% 5px no-repeat;padding-right:205px}p{margin:11px 0 22px;overflow:hidden}pre{white-space:pre-wrap;}ins{color:#777;text-decoration:none}a img{border:0}@media screen and (max-width:772px){body{background:none;margin-top:0;max-width:none;padding-right:0}}#logo{background:url(//www.google.com/images/branding/googlelogo/1x/googlelogo_color_150x54dp.png) no-repeat;margin-left:-5px}@media only screen and (min-resolution:192dpi){#logo{background:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) no-repeat 0% 0%/100% 100%;-moz-border-image:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) 0}}@media only screen and (-webkit-min-device-pixel-ratio:2){#logo{background:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) no-repeat;-webkit-background-size:100% 100%}}#logo{display:inline-block;height:54px;width:150px}</style><main id=\"af-error-container\" role=\"main\"><a href=//www.google.com><span id=logo aria-label=Google role=img></span></a><p><b>400.</b> <ins>That’s an error.</ins><p>The server cannot process the request because it is malformed. It should not be retried. <ins>That’s all we know.</ins></main>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function Service.__del__ at 0x00000229980BFCE0>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\shake\\Desktop\\Projects\\Flip-Finder\\server\\env\\Lib\\site-packages\\selenium\\webdriver\\common\\service.py\", line 189, in __del__\n",
      "    self.stop()\n",
      "  File \"c:\\Users\\shake\\Desktop\\Projects\\Flip-Finder\\server\\env\\Lib\\site-packages\\selenium\\webdriver\\common\\service.py\", line 146, in stop\n",
      "    self.send_remote_shutdown_command()\n",
      "  File \"c:\\Users\\shake\\Desktop\\Projects\\Flip-Finder\\server\\env\\Lib\\site-packages\\selenium\\webdriver\\common\\service.py\", line 126, in send_remote_shutdown_command\n",
      "    request.urlopen(f\"{self.service_url}/shutdown\")\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\urllib\\request.py\", line 216, in urlopen\n",
      "    return opener.open(url, data, timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\urllib\\request.py\", line 519, in open\n",
      "    response = self._open(req, data)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\urllib\\request.py\", line 536, in _open\n",
      "    result = self._call_chain(self.handle_open, protocol, protocol +\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\urllib\\request.py\", line 496, in _call_chain\n",
      "    result = func(*args)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\urllib\\request.py\", line 1377, in http_open\n",
      "    return self.do_open(http.client.HTTPConnection, req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\urllib\\request.py\", line 1348, in do_open\n",
      "    h.request(req.get_method(), req.selector, req.data, headers,\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\http\\client.py\", line 1282, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\http\\client.py\", line 1328, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\http\\client.py\", line 1277, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\http\\client.py\", line 1037, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\http\\client.py\", line 975, in send\n",
      "    self.connect()\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\http\\client.py\", line 941, in connect\n",
      "    self.sock = self._create_connection(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\socket.py\", line 843, in create_connection\n",
      "    exceptions.clear()  # raise only the last error\n",
      "    ^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\shake\\Desktop\\Projects\\Flip-Finder\\server\\env\\Lib\\site-packages\\requests\\models.py:974\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 974\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    977\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\Python311\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Program Files\\Python311\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[1;32mC:\\Program Files\\Python311\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 25\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Replace 'your_image.jpg' with the path to your image file\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Replace 'your_oauth_token' with your actual OAuth token\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mupload_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m response\n",
      "Cell \u001b[1;32mIn[23], line 21\u001b[0m, in \u001b[0;36mupload_image\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStatus code:\u001b[39m\u001b[38;5;124m'\u001b[39m, response\u001b[38;5;241m.\u001b[39mstatus_code)\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResponse:\u001b[39m\u001b[38;5;124m'\u001b[39m, response\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\shake\\Desktop\\Projects\\Flip-Finder\\server\\env\\Lib\\site-packages\\requests\\models.py:978\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    977\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[1;32m--> 978\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "def upload_image(image_path):\n",
    "    url = \"https://lens.google.com/upload\"\n",
    "    headers = {\n",
    "        'Content-Type': 'multipart/form-data',\n",
    "    }\n",
    "\n",
    "    with open(image_path, 'rb') as image_file:\n",
    "        files = {\n",
    "            'image': (image_path, image_file, 'image/jpeg')\n",
    "        }\n",
    "        \n",
    "        response = requests.post(url, headers=headers, files=files)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        print('Image uploaded successfully')\n",
    "        print('Response:', response.json())\n",
    "    else:\n",
    "        print('Failed to upload image')\n",
    "        print('Status code:', response.status_code)\n",
    "        print('Response:', response.text)\n",
    "    return response.json()\n",
    "\n",
    "# Replace 'your_image.jpg' with the path to your image file\n",
    "# Replace 'your_oauth_token' with your actual OAuth token\n",
    "response = upload_image('image.jpg')\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Browser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Start a browser session (this example uses Chrome, but you can use Firefox by changing 'chrome' to 'firefox')\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mBrowser\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirefox\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m browser:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Open the URL where the form is located\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.google.com\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m     browser\u001b[38;5;241m.\u001b[39mvisit(url)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Browser' is not defined"
     ]
    }
   ],
   "source": [
    "# Start a browser session (this example uses Chrome, but you can use Firefox by changing 'chrome' to 'firefox')\n",
    "with Browser('firefox') as browser:\n",
    "    # Open the URL where the form is located\n",
    "    url = \"https://www.google.com\"\n",
    "    browser.visit(url)\n",
    "    time.sleep(3)\n",
    "    # find the search by image button\n",
    "    image_button = browser.find_by_css('nDcEnd')\n",
    "    image_button.click()\n",
    "\n",
    "    time.sleep(1)\n",
    "    # Find the file input element and upload the image\n",
    "    file_input = browser.find_by_name('encoded_image')  # Adjust the selector based on your form\n",
    "    print(file_input)\n",
    "    \n",
    "    file_input.fill('image.jpg')\n",
    "    time.sleep(3)\n",
    "    # Optionally, fill other form fields if necessary\n",
    "    # browser.find_by_name('other_field').fill('value')\n",
    "\n",
    "    # Submit the form\n",
    "    # submit_button = browser.find_by_name('submit')  # Adjust the selector based on your form\n",
    "    # submit_button.click()\n",
    "\n",
    "    # Optionally, wait for some response or next page to load\n",
    "    browser.is_text_present('Success', wait_time=10)  # Adjust based on the expected success message\n",
    "\n",
    "    # Print the URL of the current page (can be used to verify the navigation)\n",
    "    print(browser.url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://scontent-iad3-1.xx.fbcdn.net/v/t45.5328-4/451217840_498240572573817_8769391673754606793_n.jpg?stp=c1.0.260.260a_dst-jpg_p261x260&_nc_cat=104&ccb=1-7&_nc_sid=247b10&_nc_ohc=NdrGafwVUcAQ7kNvgFoDr3C&_nc_ht=scontent-iad3-1.xx&oh=00_AYCm4sE3NU_67iEHilS0Je-MLtQLmRPXTgCBtyYwBZNLng&oe=669CECEB\n"
     ]
    }
   ],
   "source": [
    "# NOTE: ONLY EBAY IMAGES ARE WORKING RIGHT NOW\n",
    "# FACEBOOK IMAGES RETURN ERROR (Probably have bot auth.)\n",
    "# MAYBE PASS THEM THROUGH A LINK GENERATOR FIRST\n",
    "\n",
    "image_url = facebook_listings[\"image_url\"][0]\n",
    "print(image_url)\n",
    "# image_filename = wget.download(image_url, \"image.jpg\")\n",
    "image_url = \"https://i.imgur.com/RQC5FHC.jpeg\"\n",
    "google_lens_soup = search_google_lens(image_url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 ('virtualenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "d0dea307777b2f4630875d1396a32912501fdae588fa34a4a74f40b8188c0617"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
